{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bbt3C49scLn"
      },
      "source": [
        "# Lab1-Assignment\n",
        "\n",
        "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
        "\n",
        "This notebook describes the assignment for Lab 1 of the text mining course.\n",
        "\n",
        "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
        "\n",
        "We assume you have worked through the following notebooks:\n",
        "* **Lab1.1-introduction**\n",
        "* **Lab1.2-introduction-to-NLTK**\n",
        "* **Lab1.3-introduction-to-spaCy**\n",
        "\n",
        "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKPAjYM3scLt"
      },
      "source": [
        "## Credits\n",
        "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZawkxDv-scLu"
      },
      "source": [
        "## Tip: how to read a file from disk\n",
        "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qz9DNSRbscLv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eWm3YRNUscLx",
        "outputId": "ee4902b7-6425-4f52-d11b-f62c004b447c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Lab1-apple-samsung-example.txt\n",
            "does path exist? -> True\n"
          ]
        }
      ],
      "source": [
        "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
        "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
        "print(path_to_file)\n",
        "print('does path exist? ->', Path.exists(path_to_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Taklgv3OscLy"
      },
      "source": [
        "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8hdYdtTlscLz",
        "outputId": "338dc6e7-dd80-41e7-9691-8c1c5dd52927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of characters 1139\n"
          ]
        }
      ],
      "source": [
        "with open(path_to_file) as infile:\n",
        "    text = infile.read()\n",
        "\n",
        "print('number of characters', len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkGPx0xscLz"
      },
      "source": [
        "## [total points: 4] Exercise 1: NLTK\n",
        "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yDItilV2scL1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "vLvybu8XtCd0",
        "outputId": "3a9fc801-4701-4b5d-f32a-b917d0da5767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WiVA7Lq4scL2"
      },
      "outputs": [],
      "source": [
        "sentences_nltk = sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cflSt9yFscL3"
      },
      "outputs": [],
      "source": [
        "tokens_per_sentence = []\n",
        "for sentence_nltk in sentences_nltk:\n",
        "    sent_tokens = word_tokenize(sentence_nltk)\n",
        "    tokens_per_sentence.append(sent_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LirZ8w0scL4"
      },
      "source": [
        "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HLO0gD5wscL5",
        "outputId": "19d24a71-9263-4ac2-bd07-c7bec1f04b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
            "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
          ]
        }
      ],
      "source": [
        "sent_id = 1\n",
        "print('SENTENCE', sentences_nltk[sent_id])\n",
        "print('TOKENS', tokens_per_sentence[sent_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqOr0VR3scL5"
      },
      "source": [
        "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
        "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
        "\n",
        "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "H3krcCpOtcv1",
        "outputId": "9ee58afe-d6fd-4678-c9ac-ef9f18d79fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XLzAqXmdscL6",
        "outputId": "11dce180-9d8e-469f-cbc1-d4db44625207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]\n",
            "[('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]\n",
            "[('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n",
            "[('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]\n",
            "[('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]\n",
            "[('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "pos_tags_per_sentence = []\n",
        "for tokens in tokens_per_sentence:\n",
        "    token_tag = nltk.pos_tag(tokens)\n",
        "    pos_tags_per_sentence.append(token_tag)\n",
        "    print(token_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VWyzQhvYscL6",
        "outputId": "e50f1eb6-c2f9-4be5-c5d6-7f148dde494d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')], [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')], [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")], [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')], [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')], [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]]\n"
          ]
        }
      ],
      "source": [
        "print(pos_tags_per_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THDPeEDVscL7"
      },
      "source": [
        "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
        "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
        "\n",
        "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "7dm3ZQqktuUr",
        "outputId": "24ea36f4-b807-468b-d6c2-fa978dcf9f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "A7B8hdhtscL7",
        "outputId": "a90dcbe8-bb4f-4bca-c68f-c444241003c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  https/NN\n",
            "  :/:\n",
            "  //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ\n",
            "  Documents/NNS\n",
            "  filed/VBN\n",
            "  to/TO\n",
            "  the/DT\n",
            "  (ORGANIZATION San/NNP Jose/NNP)\n",
            "  federal/JJ\n",
            "  court/NN\n",
            "  in/IN\n",
            "  (GPE California/NNP)\n",
            "  on/IN\n",
            "  November/NNP\n",
            "  23/CD\n",
            "  list/NN\n",
            "  six/CD\n",
            "  (ORGANIZATION Samsung/NNP)\n",
            "  products/NNS\n",
            "  running/VBG\n",
            "  the/DT\n",
            "  ``/``\n",
            "  Jelly/RB\n",
            "  (GPE Bean/NNP)\n",
            "  ''/''\n",
            "  and/CC\n",
            "  ``/``\n",
            "  Ice/NNP\n",
            "  Cream/NNP\n",
            "  Sandwich/NNP\n",
            "  ''/''\n",
            "  operating/VBG\n",
            "  systems/NNS\n",
            "  ,/,\n",
            "  which/WDT\n",
            "  (PERSON Apple/NNP)\n",
            "  claims/VBZ\n",
            "  infringe/VB\n",
            "  its/PRP$\n",
            "  patents/NNS\n",
            "  ./.)\n",
            "(S\n",
            "  The/DT\n",
            "  six/CD\n",
            "  phones/NNS\n",
            "  and/CC\n",
            "  tablets/NNS\n",
            "  affected/VBN\n",
            "  are/VBP\n",
            "  the/DT\n",
            "  (ORGANIZATION Galaxy/NNP)\n",
            "  S/NNP\n",
            "  III/NNP\n",
            "  ,/,\n",
            "  running/VBG\n",
            "  the/DT\n",
            "  new/JJ\n",
            "  (PERSON Jelly/NNP Bean/NNP)\n",
            "  system/NN\n",
            "  ,/,\n",
            "  the/DT\n",
            "  (ORGANIZATION Galaxy/NNP)\n",
            "  Tab/NNP\n",
            "  8.9/CD\n",
            "  Wifi/NNP\n",
            "  tablet/NN\n",
            "  ,/,\n",
            "  the/DT\n",
            "  (ORGANIZATION Galaxy/NNP)\n",
            "  Tab/NNP\n",
            "  2/CD\n",
            "  10.1/CD\n",
            "  ,/,\n",
            "  (PERSON Galaxy/NNP Rugby/NNP Pro/NNP)\n",
            "  and/CC\n",
            "  (PERSON Galaxy/NNP S/NNP)\n",
            "  III/NNP\n",
            "  mini/NN\n",
            "  ./.)\n",
            "(S\n",
            "  (PERSON Apple/NNP)\n",
            "  stated/VBD\n",
            "  it/PRP\n",
            "  had/VBD\n",
            "  “/NNP\n",
            "  acted/VBD\n",
            "  quickly/RB\n",
            "  and/CC\n",
            "  diligently/RB\n",
            "  ''/''\n",
            "  in/IN\n",
            "  order/NN\n",
            "  to/TO\n",
            "  ``/``\n",
            "  determine/VB\n",
            "  that/IN\n",
            "  these/DT\n",
            "  newly/RB\n",
            "  released/VBN\n",
            "  products/NNS\n",
            "  do/VBP\n",
            "  infringe/VB\n",
            "  many/JJ\n",
            "  of/IN\n",
            "  the/DT\n",
            "  same/JJ\n",
            "  claims/NNS\n",
            "  already/RB\n",
            "  asserted/VBN\n",
            "  by/IN\n",
            "  (PERSON Apple/NNP)\n",
            "  ./.\n",
            "  ''/'')\n",
            "(S\n",
            "  In/IN\n",
            "  (GPE August/NNP)\n",
            "  ,/,\n",
            "  (PERSON Samsung/NNP)\n",
            "  lost/VBD\n",
            "  a/DT\n",
            "  (GSP US/NNP)\n",
            "  patent/NN\n",
            "  case/NN\n",
            "  to/TO\n",
            "  (GPE Apple/NNP)\n",
            "  and/CC\n",
            "  was/VBD\n",
            "  ordered/VBN\n",
            "  to/TO\n",
            "  pay/VB\n",
            "  its/PRP$\n",
            "  rival/JJ\n",
            "  $/$\n",
            "  1.05bn/CD\n",
            "  (/(\n",
            "  £0.66bn/NN\n",
            "  )/)\n",
            "  in/IN\n",
            "  damages/NNS\n",
            "  for/IN\n",
            "  copying/VBG\n",
            "  features/NNS\n",
            "  of/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION iPad/NN)\n",
            "  and/CC\n",
            "  (ORGANIZATION iPhone/NN)\n",
            "  in/IN\n",
            "  its/PRP$\n",
            "  (GPE Galaxy/NNP)\n",
            "  range/NN\n",
            "  of/IN\n",
            "  devices/NNS\n",
            "  ./.)\n",
            "(S\n",
            "  (GPE Samsung/NNP)\n",
            "  ,/,\n",
            "  which/WDT\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  world/NN\n",
            "  's/POS\n",
            "  top/JJ\n",
            "  mobile/NN\n",
            "  phone/NN\n",
            "  maker/NN\n",
            "  ,/,\n",
            "  is/VBZ\n",
            "  appealing/VBG\n",
            "  the/DT\n",
            "  ruling/NN\n",
            "  ./.)\n",
            "(S\n",
            "  A/DT\n",
            "  similar/JJ\n",
            "  case/NN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION UK/NNP)\n",
            "  found/VBD\n",
            "  in/IN\n",
            "  (GPE Samsung/NNP)\n",
            "  's/POS\n",
            "  favour/NN\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  (PERSON Apple/NNP)\n",
            "  to/TO\n",
            "  publish/VB\n",
            "  an/DT\n",
            "  apology/NN\n",
            "  making/VBG\n",
            "  clear/JJ\n",
            "  that/IN\n",
            "  the/DT\n",
            "  (LOCATION South/JJ Korean/JJ)\n",
            "  firm/NN\n",
            "  had/VBD\n",
            "  not/RB\n",
            "  copied/VBN\n",
            "  its/PRP$\n",
            "  iPad/NN\n",
            "  when/WRB\n",
            "  designing/VBG\n",
            "  its/PRP$\n",
            "  own/JJ\n",
            "  devices/NNS\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "ner_tags_per_sentence = []\n",
        "\n",
        "for tokens in tokens_per_sentence:\n",
        "    ner_tags = nltk.chunk.ne_chunk(nltk.pos_tag(tokens))\n",
        "    ner_tags_per_sentence.append(ner_tags)\n",
        "    print(ner_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FXZ6Tez1scL7",
        "outputId": "6c706a21-81fb-47a2-fa5a-887a1e0e64c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tree('S', [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), Tree('GPE', [('California', 'NNP')]), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), Tree('PERSON', [('Jelly', 'NNP'), ('Bean', 'NNP')]), ('system', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), Tree('PERSON', [('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Galaxy', 'NNP'), ('S', 'NNP')]), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]), Tree('S', [Tree('PERSON', [('Apple', 'NNP')]), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Apple', 'NNP')]), ('.', '.'), (\"''\", \"''\")]), Tree('S', [('In', 'IN'), Tree('GPE', [('August', 'NNP')]), (',', ','), Tree('PERSON', [('Samsung', 'NNP')]), ('lost', 'VBD'), ('a', 'DT'), Tree('GSP', [('US', 'NNP')]), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), Tree('GPE', [('Apple', 'NNP')]), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('iPad', 'NN')]), ('and', 'CC'), Tree('ORGANIZATION', [('iPhone', 'NN')]), ('in', 'IN'), ('its', 'PRP$'), Tree('GPE', [('Galaxy', 'NNP')]), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]), Tree('S', [Tree('GPE', [('Samsung', 'NNP')]), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]), Tree('S', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('UK', 'NNP')]), ('found', 'VBD'), ('in', 'IN'), Tree('GPE', [('Samsung', 'NNP')]), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), Tree('PERSON', [('Apple', 'NNP')]), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), Tree('LOCATION', [('South', 'JJ'), ('Korean', 'JJ')]), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')])]\n"
          ]
        }
      ],
      "source": [
        "print(ner_tags_per_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zqzf7t7scL8"
      },
      "source": [
        "### [points: 2] Exercise 1c: Constituency parsing\n",
        "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
        "\n",
        "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "I4Bqr1J3scL9"
      },
      "outputs": [],
      "source": [
        "constituent_parser = nltk.RegexpParser('''\n",
        "NP: {<DT>? <JJ>* <NN>*} # NP\n",
        "P: {<IN>}           # Preposition\n",
        "V: {<V.*>}          # Verb\n",
        "PP: {<P> <NP>}      # PP -> P NP\n",
        "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "E4RGbgP-scL9",
        "outputId": "83cd7eea-a245-472d-fcde-97905313e9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP https/NN)\n",
            "  :/:\n",
            "  (NP\n",
            "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
            "  Documents/NNS\n",
            "  (VP (V filed/VBN))\n",
            "  to/TO\n",
            "  (NP the/DT)\n",
            "  San/NNP\n",
            "  Jose/NNP\n",
            "  (NP federal/JJ court/NN)\n",
            "  (P in/IN)\n",
            "  California/NNP\n",
            "  (P on/IN)\n",
            "  November/NNP\n",
            "  23/CD\n",
            "  (NP list/NN)\n",
            "  six/CD\n",
            "  Samsung/NNP\n",
            "  products/NNS\n",
            "  (VP (V running/VBG) (NP the/DT))\n",
            "  ``/``\n",
            "  Jelly/RB\n",
            "  Bean/NNP\n",
            "  ''/''\n",
            "  and/CC\n",
            "  ``/``\n",
            "  Ice/NNP\n",
            "  Cream/NNP\n",
            "  Sandwich/NNP\n",
            "  ''/''\n",
            "  (VP (V operating/VBG))\n",
            "  systems/NNS\n",
            "  ,/,\n",
            "  which/WDT\n",
            "  Apple/NNP\n",
            "  (VP (V claims/VBZ))\n",
            "  (VP (V infringe/VB))\n",
            "  its/PRP$\n",
            "  patents/NNS\n",
            "  ./.)\n",
            "(S\n",
            "  (NP The/DT)\n",
            "  six/CD\n",
            "  phones/NNS\n",
            "  and/CC\n",
            "  tablets/NNS\n",
            "  (VP (V affected/VBN))\n",
            "  (VP (V are/VBP) (NP the/DT))\n",
            "  Galaxy/NNP\n",
            "  S/NNP\n",
            "  III/NNP\n",
            "  ,/,\n",
            "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
            "  Jelly/NNP\n",
            "  Bean/NNP\n",
            "  (NP system/NN)\n",
            "  ,/,\n",
            "  (NP the/DT)\n",
            "  Galaxy/NNP\n",
            "  Tab/NNP\n",
            "  8.9/CD\n",
            "  Wifi/NNP\n",
            "  (NP tablet/NN)\n",
            "  ,/,\n",
            "  (NP the/DT)\n",
            "  Galaxy/NNP\n",
            "  Tab/NNP\n",
            "  2/CD\n",
            "  10.1/CD\n",
            "  ,/,\n",
            "  Galaxy/NNP\n",
            "  Rugby/NNP\n",
            "  Pro/NNP\n",
            "  and/CC\n",
            "  Galaxy/NNP\n",
            "  S/NNP\n",
            "  III/NNP\n",
            "  (NP mini/NN)\n",
            "  ./.)\n",
            "(S\n",
            "  Apple/NNP\n",
            "  (VP (V stated/VBD))\n",
            "  it/PRP\n",
            "  (VP (V had/VBD))\n",
            "  “/NNP\n",
            "  (VP (V acted/VBD))\n",
            "  quickly/RB\n",
            "  and/CC\n",
            "  diligently/RB\n",
            "  ''/''\n",
            "  (PP (P in/IN) (NP order/NN))\n",
            "  to/TO\n",
            "  ``/``\n",
            "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
            "  newly/RB\n",
            "  (VP (V released/VBN))\n",
            "  products/NNS\n",
            "  (VP (V do/VBP))\n",
            "  (VP\n",
            "    (V infringe/VB)\n",
            "    (NP many/JJ)\n",
            "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
            "  claims/NNS\n",
            "  already/RB\n",
            "  (VP (V asserted/VBN))\n",
            "  (P by/IN)\n",
            "  Apple/NNP\n",
            "  ./.\n",
            "  ''/'')\n",
            "(S\n",
            "  (P In/IN)\n",
            "  August/NNP\n",
            "  ,/,\n",
            "  Samsung/NNP\n",
            "  (VP (V lost/VBD) (NP a/DT))\n",
            "  US/NNP\n",
            "  (NP patent/NN case/NN)\n",
            "  to/TO\n",
            "  Apple/NNP\n",
            "  and/CC\n",
            "  (VP (V was/VBD))\n",
            "  (VP (V ordered/VBN))\n",
            "  to/TO\n",
            "  (VP (V pay/VB))\n",
            "  its/PRP$\n",
            "  (NP rival/JJ)\n",
            "  $/$\n",
            "  1.05bn/CD\n",
            "  (/(\n",
            "  (NP £0.66bn/NN)\n",
            "  )/)\n",
            "  (P in/IN)\n",
            "  damages/NNS\n",
            "  (P for/IN)\n",
            "  (VP (V copying/VBG))\n",
            "  features/NNS\n",
            "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
            "  and/CC\n",
            "  (NP iPhone/NN)\n",
            "  (P in/IN)\n",
            "  its/PRP$\n",
            "  Galaxy/NNP\n",
            "  (NP range/NN)\n",
            "  (P of/IN)\n",
            "  devices/NNS\n",
            "  ./.)\n",
            "(S\n",
            "  Samsung/NNP\n",
            "  ,/,\n",
            "  which/WDT\n",
            "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
            "  's/POS\n",
            "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
            "  ,/,\n",
            "  (VP (V is/VBZ))\n",
            "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
            "  ./.)\n",
            "(S\n",
            "  (NP A/DT similar/JJ case/NN)\n",
            "  (PP (P in/IN) (NP the/DT))\n",
            "  UK/NNP\n",
            "  (VP (V found/VBD))\n",
            "  (P in/IN)\n",
            "  Samsung/NNP\n",
            "  's/POS\n",
            "  (NP favour/NN)\n",
            "  and/CC\n",
            "  (VP (V ordered/VBD))\n",
            "  Apple/NNP\n",
            "  to/TO\n",
            "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
            "  (VP\n",
            "    (V making/VBG)\n",
            "    (NP clear/JJ)\n",
            "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
            "  (VP (V had/VBD))\n",
            "  not/RB\n",
            "  (VP (V copied/VBN))\n",
            "  its/PRP$\n",
            "  (NP iPad/NN)\n",
            "  when/WRB\n",
            "  (VP (V designing/VBG))\n",
            "  its/PRP$\n",
            "  (NP own/JJ)\n",
            "  devices/NNS\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "constituency_output_per_sentence = []\n",
        "for token in tokens_per_sentence:\n",
        "    constituency_output = constituent_parser.parse(nltk.pos_tag(token))\n",
        "    constituency_output_per_sentence.append(constituency_output)\n",
        "    print(constituency_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EvYPy39pscL-",
        "outputId": "a6325b9b-0bb8-4e4e-9b1e-f8a025be79f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tree('S', [Tree('NP', [('https', 'NN')]), (':', ':'), Tree('NP', [('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ')]), ('Documents', 'NNS'), Tree('VP', [Tree('V', [('filed', 'VBN')])]), ('to', 'TO'), Tree('NP', [('the', 'DT')]), ('San', 'NNP'), ('Jose', 'NNP'), Tree('NP', [('federal', 'JJ'), ('court', 'NN')]), Tree('P', [('in', 'IN')]), ('California', 'NNP'), Tree('P', [('on', 'IN')]), ('November', 'NNP'), ('23', 'CD'), Tree('NP', [('list', 'NN')]), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT')])]), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), Tree('VP', [Tree('V', [('operating', 'VBG')])]), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), Tree('VP', [Tree('V', [('claims', 'VBZ')])]), Tree('VP', [Tree('V', [('infringe', 'VB')])]), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [Tree('NP', [('The', 'DT')]), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), Tree('VP', [Tree('V', [('affected', 'VBN')])]), Tree('VP', [Tree('V', [('are', 'VBP')]), Tree('NP', [('the', 'DT')])]), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT'), ('new', 'JJ')])]), ('Jelly', 'NNP'), ('Bean', 'NNP'), Tree('NP', [('system', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), Tree('NP', [('tablet', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), Tree('NP', [('mini', 'NN')]), ('.', '.')]), Tree('S', [('Apple', 'NNP'), Tree('VP', [Tree('V', [('stated', 'VBD')])]), ('it', 'PRP'), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('“', 'NNP'), Tree('VP', [Tree('V', [('acted', 'VBD')])]), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('order', 'NN')])]), ('to', 'TO'), ('``', '``'), Tree('VP', [Tree('V', [('determine', 'VB')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('these', 'DT')])])]), ('newly', 'RB'), Tree('VP', [Tree('V', [('released', 'VBN')])]), ('products', 'NNS'), Tree('VP', [Tree('V', [('do', 'VBP')])]), Tree('VP', [Tree('V', [('infringe', 'VB')]), Tree('NP', [('many', 'JJ')]), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT'), ('same', 'JJ')])])]), ('claims', 'NNS'), ('already', 'RB'), Tree('VP', [Tree('V', [('asserted', 'VBN')])]), Tree('P', [('by', 'IN')]), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]), Tree('S', [Tree('P', [('In', 'IN')]), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), Tree('VP', [Tree('V', [('lost', 'VBD')]), Tree('NP', [('a', 'DT')])]), ('US', 'NNP'), Tree('NP', [('patent', 'NN'), ('case', 'NN')]), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), Tree('VP', [Tree('V', [('was', 'VBD')])]), Tree('VP', [Tree('V', [('ordered', 'VBN')])]), ('to', 'TO'), Tree('VP', [Tree('V', [('pay', 'VB')])]), ('its', 'PRP$'), Tree('NP', [('rival', 'JJ')]), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), Tree('NP', [('£0.66bn', 'NN')]), (')', ')'), Tree('P', [('in', 'IN')]), ('damages', 'NNS'), Tree('P', [('for', 'IN')]), Tree('VP', [Tree('V', [('copying', 'VBG')])]), ('features', 'NNS'), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT'), ('iPad', 'NN')])]), ('and', 'CC'), Tree('NP', [('iPhone', 'NN')]), Tree('P', [('in', 'IN')]), ('its', 'PRP$'), ('Galaxy', 'NNP'), Tree('NP', [('range', 'NN')]), Tree('P', [('of', 'IN')]), ('devices', 'NNS'), ('.', '.')]), Tree('S', [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), Tree('VP', [Tree('V', [('is', 'VBZ')]), Tree('NP', [('the', 'DT'), ('world', 'NN')])]), (\"'s\", 'POS'), Tree('NP', [('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN')]), (',', ','), Tree('VP', [Tree('V', [('is', 'VBZ')])]), Tree('VP', [Tree('V', [('appealing', 'VBG')]), Tree('NP', [('the', 'DT'), ('ruling', 'NN')])]), ('.', '.')]), Tree('S', [Tree('NP', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN')]), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('the', 'DT')])]), ('UK', 'NNP'), Tree('VP', [Tree('V', [('found', 'VBD')])]), Tree('P', [('in', 'IN')]), ('Samsung', 'NNP'), (\"'s\", 'POS'), Tree('NP', [('favour', 'NN')]), ('and', 'CC'), Tree('VP', [Tree('V', [('ordered', 'VBD')])]), ('Apple', 'NNP'), ('to', 'TO'), Tree('VP', [Tree('V', [('publish', 'VB')]), Tree('NP', [('an', 'DT'), ('apology', 'NN')])]), Tree('VP', [Tree('V', [('making', 'VBG')]), Tree('NP', [('clear', 'JJ')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN')])])]), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('not', 'RB'), Tree('VP', [Tree('V', [('copied', 'VBN')])]), ('its', 'PRP$'), Tree('NP', [('iPad', 'NN')]), ('when', 'WRB'), Tree('VP', [Tree('V', [('designing', 'VBG')])]), ('its', 'PRP$'), Tree('NP', [('own', 'JJ')]), ('devices', 'NNS'), ('.', '.')])]\n"
          ]
        }
      ],
      "source": [
        "print(constituency_output_per_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLYIVKUnscL-"
      },
      "source": [
        "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbHK3lzYscL-"
      },
      "outputs": [],
      "source": [
        "constituent_parser_v2 = nltk.RegexpParser('''\n",
        "NP: {<DT>? <JJ>* <NN>*} # NP\n",
        "P: {<IN>}           # Preposition\n",
        "V: {<V.*>}          # Verb\n",
        "PP: {<P> <NP>}      # PP -> P NP\n",
        "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
        "NEP: {}             # ???''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYB_rnRKscL_"
      },
      "outputs": [],
      "source": [
        "constituency_v2_output_per_sentence = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su9oEUBzscL_"
      },
      "outputs": [],
      "source": [
        "print(constituency_v2_output_per_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlevM_21scMA"
      },
      "source": [
        "## [total points: 1] Exercise 2: spaCy\n",
        "Use Spacy to process the same text as you analyzed with NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HWt9MjSxscMA"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRNquhH5scMB"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text) # insert code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD1Qxjv4scMB"
      },
      "source": [
        "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opdFkQ0BscMC"
      },
      "source": [
        "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
        "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNawAvxuscMC"
      },
      "source": [
        "### [points: 3] Exercise 3a: Part of speech tagging\n",
        "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
        "\n",
        "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
        "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
        "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwT6QWn6scMC"
      },
      "source": [
        "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
        "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWMV3B2nscMD"
      },
      "source": [
        "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
        "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
        "* describe briefly the difference between constituency parsing and dependency parsing\n",
        "* describe differences between the output from NLTK and spaCy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R7e5HLSscMD"
      },
      "source": [
        "# End of this notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}